<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Automation on Chris Palmieri</title>
    <link>/categories/automation/</link>
    <description>Recent content in Automation on Chris Palmieri</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Feb 2020 22:49:26 +1000</lastBuildDate>
    
	<atom:link href="/categories/automation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Build and Manage Selenium Web Scrapers With Auto-Scrape</title>
      <link>/post/20200224-manage-selenium-web-scrapers-with-auto-scrape/</link>
      <pubDate>Sun, 23 Feb 2020 22:49:26 +1000</pubDate>
      
      <guid>/post/20200224-manage-selenium-web-scrapers-with-auto-scrape/</guid>
      <description>tl;dr Auto-scrape let&#39;s you focus on writing web scraping scripts, while it takes care of logging, data persistance, data presentation and data export, all through a modern browser-based UI. It can be run locally or deployed remotely.
 Here are some screencasts of the UI. Get it on Github.  Why Scrape the Web? Building a Selenium web scraper is almost a rite of passage for programmers starting out. Watching a computer fill out forms, click links and collect data before your eyes is not only a highly satisfying and suitably non-abstract exercise for beginners to complete - browser automation forms a foundation for frontend testing, can be used for automated research, and of course can be used to replace those expensive and unreliable humans to accomplish a wide range of business-related tasks.</description>
    </item>
    
    <item>
      <title>Use Powershell Profiles Like a Pro</title>
      <link>/post/20200210-use-powershell-profile-like-a-pro/</link>
      <pubDate>Sun, 09 Feb 2020 20:31:46 +1000</pubDate>
      
      <guid>/post/20200210-use-powershell-profile-like-a-pro/</guid>
      <description>If you do any software development in a Windows environment, you&#39;ll be spending enough time inside the Powershell (PS) console that it will be worth customizing the PS Profile to speed up your workflow.
The PS Profile is essentially a .ps1 script that is run whenever a new PS console is opened. Without going too deep into how a sysadmin might use it, the average developer will probably want to use it to quickly do a few basic things:</description>
    </item>
    
    <item>
      <title>Search Google from the Powershell Console</title>
      <link>/post/20200209-search-google-from-powershell/</link>
      <pubDate>Sun, 09 Feb 2020 18:09:03 +1000</pubDate>
      
      <guid>/post/20200209-search-google-from-powershell/</guid>
      <description>You may have seen people walking around with those awkwardEat; Sleep; Code; Repeat; brogrammer shirts. I don&#39;t like them - between the many other things that developing software requires, when I actually sit down to write code the workflow would more accurately be described as Code; Compile; Google Error; Repeat;.
This short post explains how the below gg.ps1 Powershell script can increase your productivity by opening a chrome browser and executing a Google search straight from the Powershell console.</description>
    </item>
    
    <item>
      <title>Automating Deployment of a Hugo Website to Github Pages using Powershell Scripts</title>
      <link>/post/20200207-automating-deployment-hugo-github-pages/</link>
      <pubDate>Fri, 07 Feb 2020 15:12:54 +1000</pubDate>
      
      <guid>/post/20200207-automating-deployment-hugo-github-pages/</guid>
      <description>Overview The following article describes how this blog is automatically deployed. The technology stack for this blog is:
 Source content written within the Hugo framework (a static website generator written in the Go language. Hosted by GitHub Pages, directly from this repository which contains the website build (the source code is in a separate repository). Cloudflare for cached content delivery (along with many other things).  If the technology stack for your project is completely different, this article should still provide you with:</description>
    </item>
    
  </channel>
</rss>